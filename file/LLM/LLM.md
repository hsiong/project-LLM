
# 参考
+ 大规模语言模型-从理论到实践: 作者: 张奇 / 桂韬 / 郑锐 / 黄萱菁

# Math
+ https://github.com/hsiong/learning-my-note/blob/main/ai/math/math.md


# ai 如何实现最优决策和数据分析

### 1. 数据收集与处理

- **收集数据**：首先，需要收集相关的数据。这些数据可以来自多种来源，如数据库、传感器、交易记录等。
- **数据清洗**：处理缺失值、异常值，以及不一致的数据格式，确保数据的质量。
- **特征工程**：选择、修改或创建新的数据特征，以更好地代表问题的本质，提高模型的性能。

### 2. 模型选择与训练

- **模型选择**：基于问题的类型（如分类、回归、聚类等）选择合适的机器学习或深度学习模型。
- **模型训练**：使用数据集训练选定的模型。这个过程涉及调整模型的参数，使得模型能够尽可能准确地预测或分类新的数据。

### 3. 验证与参数调优

- **交叉验证**：使用一部分数据训练模型，并用另一部分数据测试模型的性能，以验证模型的有效性。
- **参数调优**：通过调整模型的参数（如学习率、隐藏层的数量等），找到最佳的参数设置，以提高模型的准确性和泛化能力。

### 4. 决策与预测

- **决策制定**：利用训练好的模型对新的数据进行预测，为决策提供支持。AI可以识别模式和趋势，提出基于数据的建议。
- **优化策略**：通过分析模型的预测结果和实际结果之间的差异，进一步优化决策制定过程。在一些场景中，可能会使用强化学习等技术来动态调整策略，以实现长期目标。

### 5. 反馈循环

- **实施与监控**：将AI的决策应用于实际场景，并持续监控其效果。
- **持续学习**：根据新数据和反馈调整和优化模型，确保决策的准确性随时间保持或提高。

# LLM 垂域
可以看到一个垂域大模型的实现过程是, 是在不同步骤多个通用大模型累积/调优的结果

实现一个大语言模型（LLM）的垂域（即专门领域，如医疗、法律等）应用，以下是一些常用的技术：

###  **微调（Fine-tuning）**

对于特定领域的任务，可以使用领域特定的数据对通用的预训练语言模型进行微调。微调的方式包括：

- **监督学习**：使用领域标注数据，针对特定任务（如医学问答、法律文档分析等）微调模型。
- **多任务微调**：在微调过程中，结合多个相关任务，提升模型的泛化能力。

微调方法使模型能够理解和处理该领域的特定语言模式和术语。

###  **领域特定的预训练（Domain-specific Pre-training）**

通过在领域特定的文本数据上重新进行预训练，可以进一步增强模型对该领域知识的掌握。这种方式通常适用于那些领域特定的术语或语言习惯较为独特的场景。

- **例如**：在大量的医疗文献上重新预训练模型，生成一个专门用于医学领域的语言模型。

###  **持续学习（Continual Learning）**

在模型应用过程中，持续地输入新的领域数据，让模型逐渐学习新的领域知识。这种方法能让模型随着时间的推移，持续更新其领域知识库，保持最新的知识水平。

- **应用场景**：例如，法律领域不断有新的法规发布，模型可以通过增量学习的方式及时掌握新的法规内容。

### **提示工程（Prompt Engineering）**

通过设计特定的提示（prompt）来引导通用语言模型生成领域相关的回答。提示可以包含领域特定的上下文信息，确保生成的内容符合领域要求。

- **例如**：在模型提示中加入“根据医学指南回答以下问题”以确保生成的内容符合医疗规范。

### **基于知识图谱的增强（Knowledge Graph Integration）**

将领域特定的知识图谱与LLM结合，可以让模型在生成答案时参考外部知识源，从而提升生成的准确性和一致性。

- **知识图谱**：将领域的实体和关系结构化，提供背景知识和逻辑推理能力。
- **应用**：例如在法律领域，模型可以结合法律条文的知识图谱来生成更加符合法规的解释和建议。

###  **专家系统集成（Expert System Integration）**

在生成式语言模型基础上，结合基于规则的专家系统（Expert Systems），可以提升模型在特定领域的推理和决策能力。这种方法尤其适用于需要遵守固定规则或准则的领域。

- **例如**：在医疗领域，模型可以结合疾病诊断规则，辅助生成符合临床实践的诊断建议。

###  **数据增强（Data Augmentation）**

在领域数据不足的情况下，可以通过数据增强技术生成更多的领域相关数据，以提升模型的性能。数据增强方法包括：

- **同义替换**：将领域特定词汇用同义词替换生成新的训练数据。
- **句子翻译和逆翻译**：通过机器翻译将句子翻译为其他语言再翻译回来，以生成更多样的数据。

###  **多模态融合（Multimodal Integration）**

如果该领域涉及到图像、表格、结构化数据等信息，可以使用多模态模型将文本和其他形式的数据结合起来，提升模型在复杂任务中的表现。

- **例如**：在医疗领域，结合病理图片和文本报告，模型可以综合多种信息生成更加准确的诊断建议。

### **知识蒸馏（Knowledge Distillation）**

将预训练的大型语言模型中的知识迁移到一个更小的、专门领域的模型中，提升小模型的领域表现，同时保留大模型的推理能力。这种方法可以减少模型部署的计算成本。

### **自监督学习（Self-Supervised Learning）**

在领域特定的无标签数据上进行自监督学习，自动提取领域相关的特征。自监督方法利用数据中的内在结构进行训练，不需要依赖大量标注数据。

- **应用场景**：可以应用于医学文献分析、法律文本推理等。

### 检索增强生成(Retrieval-Augmented Generation)

RAG（Retrieval-Augmented Generation）是**检索增强生成**模型的简称，它结合了信息检索和生成式模型的能力，旨在通过从外部知识库中检索相关信息来增强生成模型的表现，尤其是在回答开放式问题或处理特定领域任务时。

参考链接: [Rag.md](Rag.md)

### 函数调用(Function Call)

**定义**：让 LLM 在生成过程中调用外部函数或 API，以完成模型自身无法直接处理的任务。

# ChatGLM-6B-0001-环境准备

https://zhuanlan.zhihu.com/p/647859484

### NCCL windows 安装失败

NCCL 是 Nvidia 为 linux 多显卡实现的标准, 无 windows 版本
http://www.360doc.com/content/12/0121/07/77158047_1083248145.shtml

**作用**：扩展了模型的功能，使其能够执行计算、访问数据库、获取实时数据等。

**特点**：属于 LLM 内部的机制，主要关注模型如何与外部函数接口交互。

+ ChatGLM调教指南: https://mindformers.readthedocs.io/zh-cn/latest/docs/model_cards/glm.html